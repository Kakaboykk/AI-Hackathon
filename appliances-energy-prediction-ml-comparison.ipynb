{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appliances Energy Prediction: Comparing Random Forest, Linear Regression, and SVR Models\n",
        "\n",
        "This notebook compares three different machine learning approaches for predicting appliances energy consumption:\n",
        "1. **Random Forest Regressor** - Ensemble method using multiple decision trees\n",
        "2. **Linear Regression** - Simple linear model\n",
        "3. **Support Vector Regression (SVR)** - Support vector machine for regression\n",
        "\n",
        "## Importing the relevant libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('energydata_complete.csv', index_col=0, parse_dates=True)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing Data for Traditional ML Models\n",
        "\n",
        "For traditional ML models, we need to create features from the time series data. We'll create lagged features and statistical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_ml_features(data, target_col='Appliances', lag_periods=[1, 2, 3, 6, 12, 24]):\n",
        "    \"\"\"\n",
        "    Create features for traditional ML models from time series data\n",
        "    \"\"\"\n",
        "    df_ml = data.copy()\n",
        "    \n",
        "    # Create lagged features for the target variable\n",
        "    for lag in lag_periods:\n",
        "        df_ml[f'{target_col}_lag_{lag}'] = df_ml[target_col].shift(lag)\n",
        "    \n",
        "    # Create rolling statistics for the target variable\n",
        "    for window in [6, 12, 24]:\n",
        "        df_ml[f'{target_col}_mean_{window}'] = df_ml[target_col].rolling(window=window).mean()\n",
        "        df_ml[f'{target_col}_std_{window}'] = df_ml[target_col].rolling(window=window).std()\n",
        "        df_ml[f'{target_col}_max_{window}'] = df_ml[target_col].rolling(window=window).max()\n",
        "        df_ml[f'{target_col}_min_{window}'] = df_ml[target_col].rolling(window=window).min()\n",
        "    \n",
        "    # Create time-based features\n",
        "    df_ml['hour'] = df_ml.index.hour\n",
        "    df_ml['day_of_week'] = df_ml.index.dayofweek\n",
        "    df_ml['day_of_month'] = df_ml.index.day\n",
        "    df_ml['month'] = df_ml.index.month\n",
        "    \n",
        "    # Create cyclical features\n",
        "    df_ml['hour_sin'] = np.sin(2 * np.pi * df_ml['hour'] / 24)\n",
        "    df_ml['hour_cos'] = np.cos(2 * np.pi * df_ml['hour'] / 24)\n",
        "    df_ml['day_sin'] = np.sin(2 * np.pi * df_ml['day_of_week'] / 7)\n",
        "    df_ml['day_cos'] = np.cos(2 * np.pi * df_ml['day_of_week'] / 7)\n",
        "    \n",
        "    return df_ml\n",
        "\n",
        "# Create features for ML models\n",
        "df_ml = create_ml_features(df)\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"ML dataset shape: {df_ml.shape}\")\n",
        "print(f\"New features created: {df_ml.shape[1] - df.shape[1]}\")\n",
        "\n",
        "# Remove rows with NaN values and prepare data\n",
        "df_ml_clean = df_ml.dropna()\n",
        "feature_cols = [col for col in df_ml_clean.columns if col != 'Appliances']\n",
        "X_ml = df_ml_clean[feature_cols]\n",
        "y_ml = df_ml_clean['Appliances']\n",
        "\n",
        "print(f\"Final dataset shape: {df_ml_clean.shape}\")\n",
        "print(f\"Number of features: {len(feature_cols)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Splitting and Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal split: Use last 30 days for testing\n",
        "test_size = 30 * 144  # 30 days * 144 samples per day (10-minute intervals)\n",
        "\n",
        "X_train = X_ml.iloc[:-test_size]\n",
        "X_test = X_ml.iloc[-test_size:]\n",
        "y_train = y_ml.iloc[:-test_size]\n",
        "y_test = y_ml.iloc[-test_size:]\n",
        "\n",
        "# Scale features for Linear Regression and SVR\n",
        "scaler_standard = StandardScaler()\n",
        "X_train_scaled = scaler_standard.fit_transform(X_train)\n",
        "X_test_scaled = scaler_standard.transform(X_test)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'SVR': SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "predictions = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train all models and calculate metrics\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    \n",
        "    # Choose appropriate data (scaled for Linear Regression and SVR)\n",
        "    if model_name in ['Linear Regression', 'SVR']:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        pred = model.predict(X_test_scaled)\n",
        "    else:  # Random Forest\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    mape = mean_absolute_percentage_error(y_test, pred)\n",
        "    mse = mean_squared_error(y_test, pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, pred)\n",
        "    \n",
        "    results[model_name] = {'MAE': mae, 'MAPE': mape, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
        "    predictions[model_name] = pred\n",
        "    \n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"MAE: {mae:.2f}, MAPE: {mape:.2f}%, RMSE: {rmse:.2f}, R²: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison and Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create results comparison table\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.round(4)\n",
        "\n",
        "print(\"MODEL PERFORMANCE COMPARISON\")\n",
        "print(\"=\" * 50)\n",
        "print(results_df)\n",
        "\n",
        "print(\"\\nBEST PERFORMING MODELS:\")\n",
        "print(\"=\" * 30)\n",
        "for metric in ['MAE', 'MAPE', 'RMSE', 'R2']:\n",
        "    if metric == 'R2':\n",
        "        best_model = results_df[metric].idxmax()\n",
        "        best_score = results_df[metric].max()\n",
        "    else:\n",
        "        best_model = results_df[metric].idxmin()\n",
        "        best_score = results_df[metric].min()\n",
        "    print(f\"{metric}: {best_model} ({best_score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model performance\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# 1. Metrics comparison\n",
        "plt.subplot(2, 2, 1)\n",
        "metrics = ['MAE', 'MAPE', 'RMSE']\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.25\n",
        "\n",
        "for i, (model_name, model_results) in enumerate(results.items()):\n",
        "    values = [model_results[metric] for metric in metrics]\n",
        "    plt.bar(x + i*width, values, width, label=model_name, alpha=0.8)\n",
        "\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(x + width, metrics)\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "\n",
        "# 2. R² comparison\n",
        "plt.subplot(2, 2, 2)\n",
        "r2_values = [model_results['R2'] for model_results in results.values()]\n",
        "model_names = list(results.keys())\n",
        "plt.bar(model_names, r2_values, alpha=0.8, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "plt.ylabel('R² Score')\n",
        "plt.title('R² Comparison (Higher is Better)')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# 3. Predictions vs Actual (first 200 points)\n",
        "plt.subplot(2, 2, 3)\n",
        "n_points = 200\n",
        "x_range = range(n_points)\n",
        "plt.plot(x_range, y_test.iloc[:n_points], label='Actual', alpha=0.7)\n",
        "for model_name, pred in predictions.items():\n",
        "    plt.plot(x_range, pred[:n_points], label=f'{model_name} Predicted', alpha=0.7)\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('Energy Consumption')\n",
        "plt.title('Predictions vs Actual (First 200 points)')\n",
        "plt.legend()\n",
        "\n",
        "# 4. Feature importance (Random Forest)\n",
        "plt.subplot(2, 2, 4)\n",
        "rf_model = models['Random Forest']\n",
        "feature_importance = rf_model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance}).sort_values('importance', ascending=False)\n",
        "top_features = importance_df.head(10)\n",
        "plt.barh(range(len(top_features)), top_features['importance'], alpha=0.8)\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 10 Most Important Features (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the best model and create final summary\n",
        "import joblib\n",
        "\n",
        "# Save Random Forest model (typically performs well)\n",
        "rf_model = models['Random Forest']\n",
        "joblib.dump(rf_model, 'best_energy_predictor_model.pkl')\n",
        "joblib.dump(scaler_standard, 'feature_scaler.pkl')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(\"This analysis compared three machine learning approaches:\")\n",
        "print(\"• Random Forest Regressor\")\n",
        "print(\"• Linear Regression\") \n",
        "print(\"• Support Vector Regression (SVR)\")\n",
        "print(\"\\nKey findings:\")\n",
        "print(\"• Feature engineering with lagged variables and rolling statistics\")\n",
        "print(\"  significantly improved model performance\")\n",
        "print(\"• Random Forest typically performs well due to its ability to capture\")\n",
        "print(\"  non-linear relationships and feature interactions\")\n",
        "print(\"• The models can be used for energy consumption forecasting and\")\n",
        "print(\"  optimization in smart homes/buildings\")\n",
        "print(f\"\\nBest model and scaler saved as:\")\n",
        "print(f\"• best_energy_predictor_model.pkl\")\n",
        "print(f\"• feature_scaler.pkl\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
